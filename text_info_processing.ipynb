{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/boom/.pyenv/versions/llama32/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, GenerationConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama_fast.LlamaTokenizerFast'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565 - if you loaded a llama tokenizer from a GGUF file you can ignore this message.\n",
      "2024-11-06 15:55:13.926297: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1730904913.995393   75243 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1730904914.015312   75243 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-06 15:55:14.165179: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Converting and de-quantizing GGUF tensors...:  10%|▉         | 70/723 [01:15<20:02,  1.84s/it] "
     ]
    }
   ],
   "source": [
    "model_name_or_path = \"MaziyarPanahi/Meta-Llama-3-70B-Instruct-GGUF\"\n",
    "model_file = \"Meta-Llama-3-70B-Instruct.Q2_K.gguf\"\n",
    "# unsloth/llama-3-8b-Instruct-bnb-4bit (performance ok but hallucinates on comparing levels)\n",
    "# unsloth/mistral-7b-instruct-v0.3-bnb-4bit (performance ok but hallucinates on comparing levels)\n",
    "# HuggingFaceTB/SmolLM2-1.7B-Instruct (trash or wrong prompt format)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, gguf_file = model_file)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name_or_path,\n",
    "    low_cpu_mem_usage=True,\n",
    "    device_map=\"cuda:0\",\n",
    "    gguf_file = model_file\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unrecognized model in MaziyarPanahi/Meta-Llama-3-70B-Instruct-GGUF. Should have a `model_type` key in its config.json, or contain one of the following strings in its name: albert, align, altclip, audio-spectrogram-transformer, autoformer, bark, bart, beit, bert, bert-generation, big_bird, bigbird_pegasus, biogpt, bit, blenderbot, blenderbot-small, blip, blip-2, bloom, bridgetower, bros, camembert, canine, chameleon, chinese_clip, chinese_clip_vision_model, clap, clip, clip_text_model, clip_vision_model, clipseg, clvp, code_llama, codegen, cohere, conditional_detr, convbert, convnext, convnextv2, cpmant, ctrl, cvt, dac, data2vec-audio, data2vec-text, data2vec-vision, dbrx, deberta, deberta-v2, decision_transformer, deformable_detr, deit, depth_anything, deta, detr, dinat, dinov2, distilbert, donut-swin, dpr, dpt, efficientformer, efficientnet, electra, encodec, encoder-decoder, ernie, ernie_m, esm, falcon, falcon_mamba, fastspeech2_conformer, flaubert, flava, fnet, focalnet, fsmt, funnel, fuyu, gemma, gemma2, git, glm, glpn, gpt-sw3, gpt2, gpt_bigcode, gpt_neo, gpt_neox, gpt_neox_japanese, gptj, gptsan-japanese, granite, granitemoe, graphormer, grounding-dino, groupvit, hiera, hubert, ibert, idefics, idefics2, idefics3, imagegpt, informer, instructblip, instructblipvideo, jamba, jetmoe, jukebox, kosmos-2, layoutlm, layoutlmv2, layoutlmv3, led, levit, lilt, llama, llava, llava_next, llava_next_video, llava_onevision, longformer, longt5, luke, lxmert, m2m_100, mamba, mamba2, marian, markuplm, mask2former, maskformer, maskformer-swin, mbart, mctct, mega, megatron-bert, mgp-str, mimi, mistral, mixtral, mllama, mobilebert, mobilenet_v1, mobilenet_v2, mobilevit, mobilevitv2, moshi, mpnet, mpt, mra, mt5, musicgen, musicgen_melody, mvp, nat, nemotron, nezha, nllb-moe, nougat, nystromformer, olmo, olmoe, omdet-turbo, oneformer, open-llama, openai-gpt, opt, owlv2, owlvit, paligemma, patchtsmixer, patchtst, pegasus, pegasus_x, perceiver, persimmon, phi, phi3, phimoe, pix2struct, pixtral, plbart, poolformer, pop2piano, prophetnet, pvt, pvt_v2, qdqbert, qwen2, qwen2_audio, qwen2_audio_encoder, qwen2_moe, qwen2_vl, rag, realm, recurrent_gemma, reformer, regnet, rembert, resnet, retribert, roberta, roberta-prelayernorm, roc_bert, roformer, rt_detr, rt_detr_resnet, rwkv, sam, seamless_m4t, seamless_m4t_v2, segformer, seggpt, sew, sew-d, siglip, siglip_vision_model, speech-encoder-decoder, speech_to_text, speech_to_text_2, speecht5, splinter, squeezebert, stablelm, starcoder2, superpoint, swiftformer, swin, swin2sr, swinv2, switch_transformers, t5, table-transformer, tapas, time_series_transformer, timesformer, timm_backbone, trajectory_transformer, transfo-xl, trocr, tvlt, tvp, udop, umt5, unispeech, unispeech-sat, univnet, upernet, van, video_llava, videomae, vilt, vipllava, vision-encoder-decoder, vision-text-dual-encoder, visual_bert, vit, vit_hybrid, vit_mae, vit_msn, vitdet, vitmatte, vits, vivit, wav2vec2, wav2vec2-bert, wav2vec2-conformer, wavlm, whisper, xclip, xglm, xlm, xlm-prophetnet, xlm-roberta, xlm-roberta-xl, xlnet, xmod, yolos, yoso, zamba, zoedepth",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m model_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMeta-Llama-3-70B-Instruct.Q2_K.gguf\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# unsloth/llama-3-8b-Instruct-bnb-4bit (performance ok but hallucinates on comparing levels)\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# unsloth/mistral-7b-instruct-v0.3-bnb-4bit (performance ok but hallucinates on comparing levels)\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# HuggingFaceTB/SmolLM2-1.7B-Instruct (trash or wrong prompt format)\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mAutoTokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name_or_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m model \u001b[38;5;241m=\u001b[39m AutoModelForCausalLM\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[1;32m      8\u001b[0m     model_name_or_path,\n\u001b[1;32m      9\u001b[0m     low_cpu_mem_usage\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     10\u001b[0m     device_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda:0\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     11\u001b[0m     model_file\u001b[38;5;241m=\u001b[39mmodel_file,\n\u001b[1;32m     12\u001b[0m )\n",
      "File \u001b[0;32m~/.pyenv/versions/llama32/lib/python3.11/site-packages/transformers/models/auto/tokenization_auto.py:877\u001b[0m, in \u001b[0;36mAutoTokenizer.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    875\u001b[0m         config \u001b[38;5;241m=\u001b[39m AutoConfig\u001b[38;5;241m.\u001b[39mfor_model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig_dict)\n\u001b[1;32m    876\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 877\u001b[0m         config \u001b[38;5;241m=\u001b[39m \u001b[43mAutoConfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m config_tokenizer_class \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mtokenizer_class\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(config, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto_map\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAutoTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config\u001b[38;5;241m.\u001b[39mauto_map:\n",
      "File \u001b[0;32m~/.pyenv/versions/llama32/lib/python3.11/site-packages/transformers/models/auto/configuration_auto.py:1049\u001b[0m, in \u001b[0;36mAutoConfig.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m   1046\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m pattern \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(pretrained_model_name_or_path):\n\u001b[1;32m   1047\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m CONFIG_MAPPING[pattern]\u001b[38;5;241m.\u001b[39mfrom_dict(config_dict, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39munused_kwargs)\n\u001b[0;32m-> 1049\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1050\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized model in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpretrained_model_name_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1051\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould have a `model_type` key in its \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mCONFIG_NAME\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, or contain one of the following strings \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1052\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124min its name: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(CONFIG_MAPPING\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1053\u001b[0m )\n",
      "\u001b[0;31mValueError\u001b[0m: Unrecognized model in MaziyarPanahi/Meta-Llama-3-70B-Instruct-GGUF. Should have a `model_type` key in its config.json, or contain one of the following strings in its name: albert, align, altclip, audio-spectrogram-transformer, autoformer, bark, bart, beit, bert, bert-generation, big_bird, bigbird_pegasus, biogpt, bit, blenderbot, blenderbot-small, blip, blip-2, bloom, bridgetower, bros, camembert, canine, chameleon, chinese_clip, chinese_clip_vision_model, clap, clip, clip_text_model, clip_vision_model, clipseg, clvp, code_llama, codegen, cohere, conditional_detr, convbert, convnext, convnextv2, cpmant, ctrl, cvt, dac, data2vec-audio, data2vec-text, data2vec-vision, dbrx, deberta, deberta-v2, decision_transformer, deformable_detr, deit, depth_anything, deta, detr, dinat, dinov2, distilbert, donut-swin, dpr, dpt, efficientformer, efficientnet, electra, encodec, encoder-decoder, ernie, ernie_m, esm, falcon, falcon_mamba, fastspeech2_conformer, flaubert, flava, fnet, focalnet, fsmt, funnel, fuyu, gemma, gemma2, git, glm, glpn, gpt-sw3, gpt2, gpt_bigcode, gpt_neo, gpt_neox, gpt_neox_japanese, gptj, gptsan-japanese, granite, granitemoe, graphormer, grounding-dino, groupvit, hiera, hubert, ibert, idefics, idefics2, idefics3, imagegpt, informer, instructblip, instructblipvideo, jamba, jetmoe, jukebox, kosmos-2, layoutlm, layoutlmv2, layoutlmv3, led, levit, lilt, llama, llava, llava_next, llava_next_video, llava_onevision, longformer, longt5, luke, lxmert, m2m_100, mamba, mamba2, marian, markuplm, mask2former, maskformer, maskformer-swin, mbart, mctct, mega, megatron-bert, mgp-str, mimi, mistral, mixtral, mllama, mobilebert, mobilenet_v1, mobilenet_v2, mobilevit, mobilevitv2, moshi, mpnet, mpt, mra, mt5, musicgen, musicgen_melody, mvp, nat, nemotron, nezha, nllb-moe, nougat, nystromformer, olmo, olmoe, omdet-turbo, oneformer, open-llama, openai-gpt, opt, owlv2, owlvit, paligemma, patchtsmixer, patchtst, pegasus, pegasus_x, perceiver, persimmon, phi, phi3, phimoe, pix2struct, pixtral, plbart, poolformer, pop2piano, prophetnet, pvt, pvt_v2, qdqbert, qwen2, qwen2_audio, qwen2_audio_encoder, qwen2_moe, qwen2_vl, rag, realm, recurrent_gemma, reformer, regnet, rembert, resnet, retribert, roberta, roberta-prelayernorm, roc_bert, roformer, rt_detr, rt_detr_resnet, rwkv, sam, seamless_m4t, seamless_m4t_v2, segformer, seggpt, sew, sew-d, siglip, siglip_vision_model, speech-encoder-decoder, speech_to_text, speech_to_text_2, speecht5, splinter, squeezebert, stablelm, starcoder2, superpoint, swiftformer, swin, swin2sr, swinv2, switch_transformers, t5, table-transformer, tapas, time_series_transformer, timesformer, timm_backbone, trajectory_transformer, transfo-xl, trocr, tvlt, tvp, udop, umt5, unispeech, unispeech-sat, univnet, upernet, van, video_llava, videomae, vilt, vipllava, vision-encoder-decoder, vision-text-dual-encoder, visual_bert, vit, vit_hybrid, vit_mae, vit_msn, vitdet, vitmatte, vits, vivit, wav2vec2, wav2vec2-bert, wav2vec2-conformer, wavlm, whisper, xclip, xglm, xlm, xlm-prophetnet, xlm-roberta, xlm-roberta-xl, xlnet, xmod, yolos, yoso, zamba, zoedepth"
     ]
    }
   ],
   "source": [
    "model_name_or_path = \"MaziyarPanahi/Meta-Llama-3-70B-Instruct-GGUF\"\n",
    "# unsloth/llama-3-8b-Instruct-bnb-4bit (performance ok but hallucinates on comparing levels)\n",
    "# unsloth/mistral-7b-instruct-v0.3-bnb-4bit (performance ok but hallucinates on comparing levels)\n",
    "# HuggingFaceTB/SmolLM2-1.7B-Instruct (trash or wrong prompt format)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name_or_path,\n",
    "    low_cpu_mem_usage=True,\n",
    "    device_map=\"cuda:0\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"\"\"\n",
    "Below are some blood test results for a dog.\n",
    "They contain information on the tested molecule, the detected level in the blood and the normal range of values.\n",
    "\n",
    "# BLOOD_TEST_DIAGNOSIS_DOCUMENT\n",
    "\n",
    "Certainly, here are the blood test chemical names, their detected levels, and the corresponding normal ranges:\n",
    "\n",
    "1. CPK (IU/L): Detected level: 217, Normal range: 45 - 155\n",
    "2. AST (IU/L): Detected level: 36, Normal range: 10 - 45\n",
    "3. ALT (IU/L): Detected level: 83, Normal range: 10 - 60\n",
    "4. ALP (IU/L): Detected level: 2780, Normal range: 45 - 152\n",
    "5. GGT (IU/L): Detected level: 3,0, Normal range: 0,1 - 0,13\n",
    "6. Bilirubina Tot (mg/dl): Detected level: 0,10, Normal range: 0,10 - 0,44\n",
    "7. Proteine Tot (g/dl): Detected level: 7,2, Normal range: 5,8 - 8,0\n",
    "8. Albumine (g/dl): Detected level: 3,26, Normal range: 2,6 - 3,8\n",
    "9. Globuline (g/dl): Detected level: 3,90, Normal range: 2,6 - 4,5\n",
    "10. Rapp. Alb/Glob: Detected level: 0,84, Normal range: 0,84 - 1,91\n",
    "11. Colesterolo (mg/dl): Detected level: 201, Normal range: 120 - 300\n",
    "12. Trigliceridi (mg/dl): Detected level: 158, Normal range: 30 - 95\n",
    "13. Amilasi (IU/L): Detected level: 836, Normal range: 200 - 1900\n",
    "14. Lipasi (IU/L): Detected level: 64, Normal range: 10 - 350\n",
    "15. UREA (mg/dl): Detected level: 21, Normal range: 15 - 45\n",
    "16. CREA (mg/dl): Detected level: 0,69, Normal range: 0,60 - 1,80\n",
    "17. Glucosio (mg/dl): Detected level: 88, Normal range: 70 - 110\n",
    "18. Calcio (mg/dl): Detected level: 9,80, Normal range: 8,0 - 12,0\n",
    "19. Acido Urico (mg/dl): Detected level: -, Normal range: 0,2 - 1\n",
    "20. Fosforo (mg/dl): Detected level: 3,90, Normal range: 2,5 - 5,6\n",
    "21. Sodio (mEq/L): Detected level: 150, Normal range: 144 - 155\n",
    "22. Potassio (mEq/L): Detected level: 4,9, Normal range: 3,3 - 5,4\n",
    "23. Rapp. Na/K: Detected level: 30,61, Normal range: > 27\n",
    "24. Cloro corr. (mEq/L): Detected level: 108,04, Normal range: 98 - 118\n",
    "25. HCO3 (mEq/L): Detected level: 21, Normal range: 17,0 - 25,2\n",
    "26. Div. anionico: Detected level: 23, Normal range: 12,0 - 24,0\n",
    "27. Osmolarità cal. (mOsm): Detected level: 322, Normal range: 314 - 335\n",
    "28. Ferro (μg/dl): Detected level: 114, Normal range: 100 - 280\n",
    "29. UBC (μg/dl): Detected level: 330, Normal range: 150 - 350\n",
    "30. TIBC (μg/dl): Detected level: 444, Normal range: 300 - 510\n",
    "31. Saturazione (%): Detected level: 25,68, Normal range: 30 - 60\n",
    "32. Ferritina (ng/ml): Detected level: -, Normal range: 21 - 78\n",
    "33. Aptoglobina HPT (mg/dl): Detected level: -, Normal range: 20 - 60\n",
    "34. Ac. Billari pre (μmol/L): Detected level: 0,3, Normal range: 0,3 - 9\n",
    "35. Ac. Billari post (μmol/L): Detected level: 0,6, Normal range: 0,6 - 30\n",
    "36. Alfa 2 Macroglobulina (g/L): Detected level: -, Normal range: 0,02 - 0,65\n",
    "37. Cistatina (mg/L): Detected level: 2282, Normal range: 3350 - 6550\n",
    "38. Colinesterasi (IU/L): Detected level: -, Normal range: 30 - 398\n",
    "39. LDH (IU/L): Detected level: -, Normal range: 188 - 351\n",
    "40. Fruttosamina (μmol/L): Detected level: -, Normal range: 0,2 - 9,0\n",
    "41. Lattato (mg/dl): Detected level: -, Normal range: 0,5 - 4,95\n",
    "42. Ceruloplasmina (mg/dl): Detected level: -, Normal range: 2,5 - 0,10\n",
    "43. Proteina C Reatt. (mg/dl): Detected level: -, Normal range: 0,01 - 0,10\n",
    "44. AGP (mg/ml): Detected level: -, Normal range: 0,01 - 0,10\n",
    "45. Magnesio (mg/dl): Detected level: 111, Normal range: 1,60 - 2,48\n",
    "46. Calcio Iónico (mmol/L): Detected level: 1,50, Normal range: 0,97 - 1,34\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLAMA3 Prompt Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the general prompt structure as a template\n",
    "general_structure = \"\"\"\n",
    "<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
    "You are an assistant for question-answering tasks. Use the following pieces of retrieved context in the section demarcated by \"```\" to answer the question.\n",
    "The context may contain multiple question answer pairs as an example, just answer the final question provided after the context.\n",
    "If you don't know the answer just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
    "\n",
    "{context}\n",
    "Question: {input}\n",
    "<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "\"\"\"\n",
    "\n",
    "# Define the specific question as a string\n",
    "input_question = \"\"\"\n",
    "1. For each tested molecule check the detected level.\n",
    "2. For each tested molecule analyze the normal range.\n",
    "3. For each tested molecule infer whether the detected level is outside the normal range.\n",
    "4. Select and return exclusively the molecules that fall outside the normal range, citing both the etected level and the range.\n",
    "5. Provide a comprehensive health diagnosis for the dog based on detected abnormalities.\n",
    "\"\"\"\n",
    "\n",
    "# Combine everything by formatting the general structure with context and input\n",
    "llama3_prompt = general_structure.format(context=context, input=input_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_config = GenerationConfig(\n",
    "    max_length=7000,\n",
    "    temperature=0.2,\n",
    "    top_p=0.95,\n",
    "    repetition_penalty=1.11,\n",
    "    do_sample=True,\n",
    "    use_cache=True,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    pad_token_id=tokenizer.eos_token_id,\n",
    "    transformers_version=\"4.46.2\",\n",
    ")\n",
    "\n",
    "inputs = tokenizer(llama3_prompt, return_tensors=\"pt\", return_attention_mask=True).to(\n",
    "    \"cuda:0\"\n",
    ")\n",
    "outputs = model.generate(**inputs, generation_config=generation_config)\n",
    "\n",
    "text = tokenizer.batch_decode(outputs)[0]\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MISTRAL7B Prompt Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the question as a response placeholder (this will be where the assistant response goes)\n",
    "instruction = \"\"\"1. For each tested molecule check the detected level.\n",
    "2. For each tested molecule analyze the normal range.\n",
    "3. For each tested molecule infer whether the detected level is outside the normal range.\n",
    "4. Select and return exclusively the molecules that fall outside the normal range, citing both the etected level and the range.\n",
    "5. Provide a comprehensive health diagnosis for the dog based on detected abnormalities.\n",
    "\"\"\"\n",
    "\n",
    "question = \"what is wrong with my dog?\"\n",
    "# Define the prompt structure as a template\n",
    "mistral_prompt = f\"\"\"\n",
    "### [INST] \n",
    "Instruction: {instruction}\n",
    "\n",
    "Here is the context to help:\n",
    "{context}\n",
    "\n",
    "### QUESTION:\n",
    "{question} \n",
    "\n",
    "[/INST]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_config = GenerationConfig(\n",
    "    max_length=7000,\n",
    "    temperature=0.2,\n",
    "    top_p=0.95,\n",
    "    repetition_penalty=1.11,\n",
    "    do_sample=True,\n",
    "    use_cache=True,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    pad_token_id=tokenizer.eos_token_id,\n",
    "    transformers_version=\"4.46.2\",\n",
    ")\n",
    "\n",
    "inputs = tokenizer(mistral_prompt, return_tensors=\"pt\", return_attention_mask=True).to(\n",
    "    \"cuda:0\"\n",
    ")\n",
    "outputs = model.generate(**inputs, generation_config=generation_config)\n",
    "\n",
    "text = tokenizer.batch_decode(outputs)[0]\n",
    "print(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama32",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
