{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/boom/.pyenv/versions/aivet/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n",
      "Loading checkpoint shards: 100%|██████████| 5/5 [00:02<00:00,  1.84it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "`.to` is not supported for `4-bit` or `8-bit` bitsandbytes models. Please use the model as it is, since the model has already been set to the correct devices and casted to the correct `dtype`.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      7\u001b[39m modelPath = \u001b[33m\"\u001b[39m\u001b[33mnikravan/glm-4vq\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      8\u001b[39m tokenizer = AutoTokenizer.from_pretrained(modelPath, trust_remote_code=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m model = \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodelPath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbfloat16\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mauto\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/aivet/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py:559\u001b[39m, in \u001b[36m_BaseAutoModelClass.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[39m\n\u001b[32m    557\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    558\u001b[39m         \u001b[38;5;28mcls\u001b[39m.register(config.\u001b[34m__class__\u001b[39m, model_class, exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m559\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    560\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    561\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    562\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m._model_mapping.keys():\n\u001b[32m    563\u001b[39m     model_class = _get_model_class(config, \u001b[38;5;28mcls\u001b[39m._model_mapping)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/aivet/lib/python3.11/site-packages/transformers/modeling_utils.py:3977\u001b[39m, in \u001b[36mPreTrainedModel.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[39m\n\u001b[32m   3974\u001b[39m         device_map_kwargs[\u001b[33m\"\u001b[39m\u001b[33moffload_buffers\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   3976\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_fsdp_enabled() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_deepspeed_zero3_enabled():\n\u001b[32m-> \u001b[39m\u001b[32m3977\u001b[39m         \u001b[43mdispatch_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mdevice_map_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3979\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m hf_quantizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   3980\u001b[39m     hf_quantizer.postprocess_model(model)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/aivet/lib/python3.11/site-packages/accelerate/big_modeling.py:502\u001b[39m, in \u001b[36mdispatch_model\u001b[39m\u001b[34m(model, device_map, main_device, state_dict, offload_dir, offload_index, offload_buffers, skip_keys, preload_module_classes, force_hooks)\u001b[39m\n\u001b[32m    500\u001b[39m     device = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mmusa:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdevice\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    501\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m device != \u001b[33m\"\u001b[39m\u001b[33mdisk\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m502\u001b[39m     \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    503\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    504\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    505\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mYou are trying to offload the whole model to the disk. Please use the `disk_offload` function instead.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    506\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/aivet/lib/python3.11/site-packages/transformers/modeling_utils.py:2826\u001b[39m, in \u001b[36mPreTrainedModel.to\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   2824\u001b[39m \u001b[38;5;66;03m# Checks if the model has been loaded in 8-bit\u001b[39;00m\n\u001b[32m   2825\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mquantization_method\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) == QuantizationMethod.BITS_AND_BYTES:\n\u001b[32m-> \u001b[39m\u001b[32m2826\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   2827\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m`.to` is not supported for `4-bit` or `8-bit` bitsandbytes models. Please use the model as it is, since the\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2828\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m model has already been set to the correct devices and casted to the correct `dtype`.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2829\u001b[39m     )\n\u001b[32m   2830\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mquantization_method\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) == QuantizationMethod.GPTQ:\n\u001b[32m   2831\u001b[39m     \u001b[38;5;66;03m# For GPTQ models, we prevent users from casting the model to another dytpe to restrict unwanted behaviours.\u001b[39;00m\n\u001b[32m   2832\u001b[39m     \u001b[38;5;66;03m# the correct API should be to load the model with the desired dtype directly through `from_pretrained`.\u001b[39;00m\n\u001b[32m   2833\u001b[39m     dtype_present_in_args = \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[31mValueError\u001b[39m: `.to` is not supported for `4-bit` or `8-bit` bitsandbytes models. Please use the model as it is, since the model has already been set to the correct devices and casted to the correct `dtype`."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from PIL import Image\n",
    "\n",
    "device = \"cuda:0\"\n",
    "\n",
    "modelPath = \"nikravan/glm-4vq\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(modelPath, trust_remote_code=True)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    modelPath,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    low_cpu_mem_usage=True,\n",
    "    trust_remote_code=True,\n",
    "    device_map=\"auto\",\n",
    "    use_cache=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "nlp = pipeline(\n",
    "    \"document-question-answering\",\n",
    "    model=\"impira/layoutlm-document-qa\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open(\"../data/input/Analisi Hope pagina 1.jpg\").convert(\"RGB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"Task: Extract and list all blood test details.\n",
    "\n",
    "Objective:\n",
    "1. Identify and extract **chemical names** from the blood test report.\n",
    "2. Capture the **detected levels** of each chemical.\n",
    "3. Extract the **normal range** for each corresponding chemical.\n",
    "\n",
    "Expected Output Format:\n",
    "- Chemical Name: [Name]\n",
    "  - Detected Level: [Value]\n",
    "  - Normal Range: [Min Value] - [Max Value]\n",
    "\n",
    "Please ensure accurate extraction, including any unit symbols (e.g., mg/dL, IU/L), and handle variations in formatting or alignment. Return results in a structured list format for easy readability.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp(image, query, temperature = 0.2, max_length = 2500, top_k =  1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"Task: Extract and list all blood test details.\n",
    "\n",
    "Objective:\n",
    "1. Identify and extract **chemical names** from the blood test report.\n",
    "2. Capture the **detected levels** of each chemical.\n",
    "3. Extract the **normal range** for each corresponding chemical.\n",
    "\n",
    "Expected Output Format:\n",
    "- Chemical Name: [Name]\n",
    "  - Detected Level: [Value]\n",
    "  - Normal Range: [Min Value] - [Max Value]\n",
    "\n",
    "Please ensure accurate extraction, including any unit symbols (e.g., mg/dL, IU/L), and handle variations in formatting or alignment. Return results in a structured list format for easy readability.\"\"\"\n",
    "# image=\"\"\n",
    "inputs = tokenizer.apply_chat_template(\n",
    "    [{\"role\": \"user\", \"image\": image, \"content\": query}],\n",
    "    add_generation_prompt=True,\n",
    "    tokenize=True,\n",
    "    return_tensors=\"pt\",\n",
    "    return_dict=True,\n",
    ")  # chat with image mode\n",
    "\n",
    "inputs = inputs.to(device)\n",
    "\n",
    "gen_kwargs = {\"max_length\": 2500, \"do_sample\": True, \"top_k\": 1, \"temperature\": 0.2}\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(**inputs, **gen_kwargs)\n",
    "    outputs = outputs[:, inputs[\"input_ids\"].shape[1] :]\n",
    "    print(tokenizer.decode(outputs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Extract all the blood test chemical name values, their detected level and the corresponding normal range\"\n",
    "inputs = tokenizer.apply_chat_template(\n",
    "    [{\"role\": \"user\", \"image\": image, \"content\": query}],\n",
    "    add_generation_prompt=True,\n",
    "    tokenize=True,\n",
    "    return_tensors=\"pt\",\n",
    "    return_dict=True,\n",
    ")  # chat with image mode\n",
    "\n",
    "inputs = inputs.to(device)\n",
    "\n",
    "gen_kwargs = {\"max_length\": 2500, \"do_sample\": True, \"top_k\": 1, \"temperature\": 0.2}\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(**inputs, **gen_kwargs)\n",
    "    outputs = outputs[:, inputs[\"input_ids\"].shape[1] :]\n",
    "    print(tokenizer.decode(outputs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Extract all the blood test chemical name values, their detected level and the corresponding normal range only for test values which have abnormal levels.\"\n",
    "inputs = tokenizer.apply_chat_template(\n",
    "    [{\"role\": \"user\", \"image\": image, \"content\": query}],\n",
    "    add_generation_prompt=True,\n",
    "    tokenize=True,\n",
    "    return_tensors=\"pt\",\n",
    "    return_dict=True,\n",
    ")  # chat with image mode\n",
    "\n",
    "inputs = inputs.to(device)\n",
    "\n",
    "gen_kwargs = {\"max_length\": 2500, \"do_sample\": True, \"top_k\": 1, \"temperature\": 0.2}\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(**inputs, **gen_kwargs)\n",
    "    outputs = outputs[:, inputs[\"input_ids\"].shape[1] :]\n",
    "    print(tokenizer.decode(outputs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Based on the detected test values in the blood test document as well as the reported reference ranges, identify and list the molecules which are outside the reference ranges. List the molecule name, value and the reference range. Finally perform a health diagnosis based on the abnormalities. Do not list any molecules which are within the reference range, those are considered normal.\"\n",
    "inputs = tokenizer.apply_chat_template(\n",
    "    [{\"role\": \"user\", \"image\": image, \"content\": query}],\n",
    "    add_generation_prompt=True,\n",
    "    tokenize=True,\n",
    "    return_tensors=\"pt\",\n",
    "    return_dict=True,\n",
    ")  # chat with image mode\n",
    "\n",
    "inputs = inputs.to(device)\n",
    "\n",
    "gen_kwargs = {\"max_length\": 2500, \"do_sample\": True, \"top_k\": 1, \"temperature\": 0.2}\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(**inputs, **gen_kwargs)\n",
    "    outputs = outputs[:, inputs[\"input_ids\"].shape[1] :]\n",
    "    print(tokenizer.decode(outputs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aivet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
